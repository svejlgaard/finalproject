{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparison.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_jmEhVxIv2f3Ra5ljMtg6MnpKetGJuFR",
      "authorship_tag": "ABX9TyPJLrSahf69T6i06KfCWwX1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzKtPhy6Fpy9",
        "colab_type": "code",
        "outputId": "02ae96a8-2eb6-45d5-f8eb-94f743fc836d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        }
      },
      "source": [
        "%pip install bayesian-optimization\n",
        "%pip install livelossplot\n",
        "%pip install lightgbm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, contextlib, sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import explained_variance_score, r2_score\n",
        "from sklearn.preprocessing import quantile_transform, StandardScaler, RobustScaler\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from livelossplot import PlotLosses\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import datetime\n",
        "\n",
        "%cd /content/drive/My\\ Drive/Colab\\ Notebooks\n",
        "\n",
        "np.random.seed(seed=1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.15.1)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: bokeh; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (1.4.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (1.18.4)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (20.4)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (3.13)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (7.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (2.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (47.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh; python_version >= \"3.6\"->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.2.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.15.1)\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSWV_IuMNqDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9PShidcOFOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loaddata(directory, t=True):\n",
        "  \n",
        "    feature_list = list()\n",
        "    train_data_list = list()\n",
        "    train_target_list = list()\n",
        "    name = list()\n",
        "\n",
        "\n",
        "    for i,filename in enumerate(os.listdir(directory)):\n",
        "        data_matrix = np.genfromtxt(f'{directory}/{filename}')\n",
        "        if filename == 'Data2scaled.txt': \n",
        "            name.append(filename)\n",
        "            raw_data = np.genfromtxt('data/etalon_etalon_29May20.ccfSum-telemetry.csv',delimiter=',',names=True)\n",
        "            feature_list.append(list(raw_data.dtype.names))\n",
        "            test_data = data_matrix[:,[i for i in range(len(data_matrix[1])) if i!=1]]\n",
        "            test_target = data_matrix[:,1]\n",
        "        else:\n",
        "            train_data_list.append(data_matrix[:,[i for i in range(len(data_matrix[1])) if i!=1]])\n",
        "            train_target_list.append(data_matrix[:,1])\n",
        "    feature_list = feature_list[0]\n",
        "    feature_list.remove('RV')    \n",
        "\n",
        "\n",
        "    if t == True:\n",
        "      train_data_list = [quantile_transform(data,n_quantiles=100,copy=True) for data in train_data_list]\n",
        "      test_data = quantile_transform(test_data,n_quantiles=100,copy=True)\n",
        "      train_data_torch = [torch.from_numpy(data).unsqueeze(dim=1).float().to(gpu) for data in train_data_list]\n",
        "      train_target_torch = [torch.from_numpy(data).unsqueeze(dim=1).float().to(gpu) for data in train_target_list]\n",
        "      test_data_torch, test_target_torch = torch.from_numpy(np.array(test_data)).unsqueeze(dim=1).float().to(gpu), torch.from_numpy(np.array(test_target)).float().to(gpu)\n",
        "      return train_data_torch, train_target_torch, test_data_torch, test_target_torch, np.array(feature_list,dtype=str)\n",
        "\n",
        "    \n",
        "    elif t == False:\n",
        "      train_data_list = [quantile_transform(data,n_quantiles=100,copy=True) for data in train_data_list]\n",
        "      test_data = quantile_transform(test_data,n_quantiles=100,copy=True)\n",
        "      train_data = np.concatenate(train_data_list, axis=0)\n",
        "      train_target = np.concatenate(train_target_list, axis=0)\n",
        "      train_data = np.delete(train_data, 0, 1)\n",
        "      test_data = np.delete(test_data, 0, 1)\n",
        "      return train_data, train_target, test_data, test_target, name[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29po0sRCdqWK",
        "colab_type": "text"
      },
      "source": [
        "**Loading in data:** For gpu (torch-based, t=True) and cpu (sklearn-based, t=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0PvAGEGOkih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_torch, train_target_torch, test_data_torch, test_target_torch, feature_list = loaddata('Scaleddata', t=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQqn7JXe2MXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_numpy, train_target_numpy, test_data_numpy, test_target_numpy, name = loaddata('Scaleddata', t=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SpkwRMu6ESC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, inputsize, layers, hiddensize, drop_out):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.inputsize = inputsize\n",
        "        self.hiddensize = hiddensize\n",
        "        self.layers = layers\n",
        "        self.drop_out = drop_out\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.inputsize, hidden_size = self.hiddensize, num_layers=layers, dropout=drop_out)\n",
        "        self.hidden2radial = nn.Linear(in_features=hiddensize, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        #x = F.elu(x)\n",
        "        x = self.hidden2radial(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTo46Fq2dNqe",
        "colab_type": "text"
      },
      "source": [
        "**Bayesian Optimization:** A generalized version to optimize both torch based and sklearn based algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3bCGJxUHhIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val(inputsize: int, algorithm, data, targets, **params):\n",
        "    param_list = list()\n",
        "    for arg in params.values():\n",
        "      param_list.append(arg)\n",
        "\n",
        "    if algorithm == LSTMTagger:\n",
        "      estimator = algorithm(inputsize, int(param_list[2]), int(param_list[1]), param_list[0])\n",
        "      optimizer = torch.optim.Adam(estimator.parameters(),lr=param_list[3])\n",
        "      judge = list()\n",
        "      estimator = estimator.to(gpu)\n",
        "      criterion = nn.MSELoss()\n",
        "      for i,valdata in enumerate(train_data_torch):\n",
        "          traindata = train_data_torch[:i] + train_data_torch[i+1:]\n",
        "          traintarget = train_target_torch[:i] + train_target_torch[i+1:]\n",
        "          valtarget = train_target_torch[i]\n",
        "          judge_list = list()\n",
        "          n_epochs = 100\n",
        "          for e in range(n_epochs):\n",
        "            estimator.train()\n",
        "            epoch_losses = list()\n",
        "            epoch_evs = list()\n",
        "            acc_list = list()\n",
        "            loss_list = list()\n",
        "            for batch in range(len(traindata)):\n",
        "              estimator.zero_grad()\n",
        "              optimizer.zero_grad() \n",
        "              prediction = estimator(traindata[batch])\n",
        "              target = traintarget[batch]\n",
        "              # Calculating the loss function\n",
        "              loss = criterion(prediction.squeeze(dim=2), target)\n",
        "              # Calculating the gradient\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "            with torch.no_grad():\n",
        "              estimator.eval()\n",
        "              train_prediction = estimator(valdata).squeeze(dim=1)\n",
        "              loss_list.append( float(criterion((train_prediction),valtarget).detach().cpu()) )\n",
        "              acc_list.append( explained_variance_score(valtarget.cpu(), train_prediction.cpu()) )\n",
        "              #print(e, np.mean(loss_list),np.mean(acc_list))\n",
        "            judge_list.append(np.mean(acc_list))\n",
        "      return np.mean(judge_list)\n",
        "\n",
        "    else:\n",
        "      for key in params.keys():\n",
        "        if params[key] >= 1:\n",
        "          params[key] = int(params[key])\n",
        "      estimator = algorithm(random_state=27, **params)\n",
        "      cval = cross_val_score(estimator, data, targets, cv=5,scoring='explained_variance')\n",
        "      return cval.mean()\n",
        "\n",
        "def optimize(algorithm, data, targets, params, n_iter):\n",
        "    def crossval_wrapper(data=data, targets=targets, **params):\n",
        "        return val(inputsize = 27,\n",
        "                   algorithm = algorithm, \n",
        "                   data = data, \n",
        "                   targets = targets, \n",
        "                   **params)\n",
        "\n",
        "    optimizer = BayesianOptimization(f=crossval_wrapper, \n",
        "                                     pbounds=params, \n",
        "                                     random_state=27, \n",
        "                                     verbose=2)\n",
        "    optimizer.maximize(init_points=2, n_iter=n_iter)\n",
        "\n",
        "    return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrLZo9b3nlvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_list = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVsm6am4dHyV",
        "colab_type": "text"
      },
      "source": [
        "**Long short term memory:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVWYj3SF6I6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "209c3d06-981d-48b0-a4c9-d4b9584fe405"
      },
      "source": [
        "params_LSTM = {\"layers\": (1, 3),\n",
        "               \"hiddensize\": (100, 400),\n",
        "               \"drop_out\": (0.2, 0.6),\n",
        "               \"lr\": (0.0001, 0.00001)}\n",
        "\n",
        "BO_LSTM = optimize(algorithm = LSTMTagger, data = train_data_torch, targets = train_target_torch, params = params_LSTM, n_iter = 6)\n",
        "\n",
        "print(BO_LSTM.max)\n",
        "\n",
        "max_params_LSTM = BO_LSTM.max['params']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | drop_out  | hidden... |  layers   |    lr     |\n",
            "-------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8076  \u001b[0m | \u001b[0m 0.3703  \u001b[0m | \u001b[0m 344.4   \u001b[0m | \u001b[0m 2.471   \u001b[0m | \u001b[0m 2.188e-0\u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8857  \u001b[0m | \u001b[95m 0.3534  \u001b[0m | \u001b[95m 393.8   \u001b[0m | \u001b[95m 2.786   \u001b[0m | \u001b[95m 8.113e-0\u001b[0m |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7MiK4ZDGvwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "judge = list()\n",
        "for i,valdata in enumerate(train_data_torch):\n",
        "      model = LSTMTagger(27,layers=int(max_params_LSTM['layers']), hiddensize=int(max_params_LSTM['hiddensize']),drop_out=max_params_LSTM['drop_out']).to(gpu)\n",
        "      optimizer = optim.Adam(model.parameters(),lr=max_params_LSTM['lr'])\n",
        "\n",
        "      traindata = train_data_torch[:i] + train_data_torch[i+1:]\n",
        "      traintarget = train_target_torch[:i] + train_target_torch[i+1:]\n",
        "      valtarget = train_target_torch[i]\n",
        "      judge_list = list()\n",
        "\n",
        "      plotlosses = PlotLosses()\n",
        "      n_epochs = 100\n",
        "      for e in range(n_epochs):\n",
        "          model.train()\n",
        "          epoch_losses = list()\n",
        "          epoch_evs = list()\n",
        "          acc_list = list()\n",
        "          loss_list = list()\n",
        "          for batch in range(len(traindata)):\n",
        "              model.zero_grad()\n",
        "              optimizer.zero_grad() \n",
        "              prediction = model(traindata[batch])\n",
        "              target = traintarget[batch]\n",
        "              # Calculating the loss function\n",
        "              loss = criterion(prediction.squeeze(dim=2), target)\n",
        "              epoch_losses.append(float(loss))\n",
        "              evs = explained_variance_score(target.squeeze(dim=1).detach().cpu().numpy(),prediction.squeeze(dim=1).detach().cpu().numpy())\n",
        "              epoch_evs.append(evs)\n",
        "              # Calculating the gradient\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "          with torch.no_grad():\n",
        "              model.eval()\n",
        "              train_prediction = model(valdata).squeeze(dim=1)\n",
        "              loss_list.append( float(criterion((train_prediction),valtarget).detach().cpu()) )\n",
        "              acc_list.append( explained_variance_score(valtarget.cpu(), train_prediction.cpu()) )\n",
        "          print(e, np.mean(epoch_losses), np.mean(epoch_evs))\n",
        "          judge_list.append(np.mean(acc_list))\n",
        "      judge.append([np.mean(judge_list),model])\n",
        "sorted(judge, key=lambda x: x[0])\n",
        "winner = judge[0]\n",
        "model_list.append(winner[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIllPyl9dCHu",
        "colab_type": "text"
      },
      "source": [
        "**Light GBM:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ljVMPa9F0BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_LGBM = {'num_leaves': (2, 5),\n",
        "               #'max_depth': (50, 500),\n",
        "               'learning_rate': (0.01, 1)}\n",
        "\n",
        "BO_LGBM = optimize(algorithm = lgb.LGBMRegressor, data = train_data_numpy, targets = train_target_numpy, params = params_LGBM, n_iter=30)\n",
        "\n",
        "print(BO_LGBM.max)\n",
        "\n",
        "max_params_LGBM = BO_LGBM.max['params']\n",
        "\n",
        "model_LGBM = lgb.LGBMRegressor(num_leaves = int(max_params_LGBM['num_leaves']), \n",
        "                               #max_depth= int(max_params_LGBM['max_depth']), \n",
        "                               learning_rate = max_params_LGBM['learning_rate']\n",
        "                               )\n",
        "model_LGBM.fit(train_data_numpy, train_target_numpy)\n",
        "\n",
        "model_list.append(model_LGBM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oag1LLnWc5bs",
        "colab_type": "text"
      },
      "source": [
        "**XG Boost:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXTtPVSyu4sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_XGB = {\"eta\": (0.1, 0.5),\n",
        "               \"max_depth\": (1, 10),\n",
        "               \"num_round\": (1, 40),\n",
        "              \"n_esimators\": (2, 10)}\n",
        "\n",
        "BO_XGB = optimize(algorithm = xgb.XGBRegressor, data = train_data_numpy, targets = train_target_numpy, params = params_XGB, n_iter=30)\n",
        "\n",
        "print(BO_XGB.max)\n",
        "\n",
        "max_params_XGB = BO_XGB.max['params']\n",
        "\n",
        "model_XGB = xgb.XGBRegressor(max_depth = int(max_params_XGB['max_depth']), \n",
        "                             num_round = int(max_params_XGB['num_round']),\n",
        "                             eta = max_params_XGB['eta'],\n",
        "                             n_estimators = int(max_params_XGB['n_estimators'])\n",
        "                             )             \n",
        "\n",
        "model_XGB.fit(train_data_numpy, train_target_numpy)     \n",
        "\n",
        "model_list.append(model_XGB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vXlbl5le3cX",
        "colab_type": "text"
      },
      "source": [
        "**Ordinary Least Squares:** No need for Bayesian Optimization \\\\\n",
        "**Multi-Layer Perception:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcYiHBPND68R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_MLP = {\"hidden_layer_sizes\": (1, 200),\n",
        "               \"alpha\": (0, 0.4),\n",
        "               \"learning_rate_init\": (0.00001, 1)}\n",
        "\n",
        "BO_MLP = optimize(algorithm = MLPRegressor, data = train_data_numpy, targets = train_target_numpy, params = params_MLP, n_iter=30)\n",
        "\n",
        "print(BO_MLP.max)\n",
        "\n",
        "max_params_MLP = BO_MLP.max['params']\n",
        "\n",
        "model_MLP = MLPRegressor(hidden_layer_sizes= int(max_params_MLP['hidden_layer_sizes']),\n",
        "                         alpha = max_params_MLP['alpha'],\n",
        "                         learning_rate_init= max_params_MLP['learning_rate_init']\n",
        "                         )\n",
        "model_MLP.fit(train_data_numpy, train_target_numpy)\n",
        "\n",
        "model_list.append(model_MLP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMX4wqpqVRJI",
        "colab_type": "text"
      },
      "source": [
        "**Ordinary Least Squares:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcHvFwMT3Ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_OLS = linear_model.LinearRegression()\n",
        "model_OLS.fit(train_data_numpy, train_target_numpy)\n",
        "model_list.append(model_OLS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC6vHDdOVkBA",
        "colab_type": "text"
      },
      "source": [
        "**Plot:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM9hmafAhHVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time = test_data_torch.cpu().squeeze().detach().numpy()[:,0]\n",
        "\n",
        "fig = plt.figure('All models')\n",
        "colorlist = ['#c51b7d', '#e9a3c9', '#fde0ef', '#e6f5d0', '#a1d76a', '#4d9221']\n",
        "#colorlist = colorlist[::-1]\n",
        "plt.plot(time, test_target_numpy, linestyle='-', linewidth=3, label='True', color=colorlist[-1])\n",
        "for i,model in enumerate(model_list):\n",
        "  if i == 0:\n",
        "    prediction = model(test_data_torch).squeeze(dim=1).detach().cpu().numpy()\n",
        "    plt.plot(time, prediction, linestyle='-',label=f'{model}'.split('(')[0].replace('Tagger',''), color=colorlist[i])\n",
        "  elif i == len(model_list)-1:\n",
        "    plt.plot(time, model.predict(test_data_numpy),linestyle='-',label=f'{model}'.split('(')[0].replace('Regression',''), color=colorlist[i])\n",
        "  else:\n",
        "    plt.plot(time, model.predict(test_data_numpy),linestyle='-',label=f'{model}'.split('(')[0].replace('Regressor',''), color=colorlist[i])\n",
        "plt.legend(loc='best')\n",
        "plt.title(f\"Testing on {name.replace('scaled.txt','')}\")\n",
        "plt.xlabel('Scaled time')\n",
        "plt.ylabel('Scaled drift')\n",
        "plt.style.use('seaborn-white')\n",
        "plt.style.use('seaborn-ticks')\n",
        "fig.patch.set_facecolor('#f2f2f2')\n",
        "cur_time = str(datetime.datetime.now())\n",
        "cur_time = cur_time.split('.')[0]\n",
        "cur_time = cur_time.replace(' ','')\n",
        "cur_time = cur_time.replace('-','')\n",
        "cur_time = cur_time.replace(':','')\n",
        "print(cur_time)\n",
        "fig.savefig(f\"TotalTest{name.replace('scaled.txt','')}_{cur_time}.png\", facecolor=fig.get_facecolor(), format='png', dpi=1200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywSe4IbvP0ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
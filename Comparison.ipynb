{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparison.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_jmEhVxIv2f3Ra5ljMtg6MnpKetGJuFR",
      "authorship_tag": "ABX9TyMik++QxBJ8+x840LHFd2nM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzKtPhy6Fpy9",
        "colab_type": "code",
        "outputId": "a9c3df82-32d6-4d06-bc68-b6858acc43a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        }
      },
      "source": [
        "%pip install bayesian-optimization\n",
        "%pip install livelossplot\n",
        "%pip install lightgbm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os, contextlib, sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import explained_variance_score, r2_score\n",
        "from sklearn.preprocessing import quantile_transform, StandardScaler, RobustScaler\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from livelossplot import PlotLosses\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "%cd /content/drive/My\\ Drive/Colab\\ Notebooks\n",
        "\n",
        "np.random.seed(seed=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.15.1)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: matplotlib; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.2.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: bokeh; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from livelossplot) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (1.18.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib; python_version >= \"3.6\"->livelossplot) (2.4.7)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (47.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (20.4)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (7.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (2.11.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (3.13)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh; python_version >= \"3.6\"->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.2.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh; python_version >= \"3.6\"->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.15.1)\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSWV_IuMNqDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9PShidcOFOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loaddata(directory, t=True):\n",
        "  \n",
        "    feature_list = list()\n",
        "    train_data_list = list()\n",
        "    train_target_list = list()\n",
        "    name = list()\n",
        "\n",
        "\n",
        "    for i,filename in enumerate(os.listdir(directory)):\n",
        "        data_matrix = np.genfromtxt(f'{directory}/{filename}')\n",
        "        if filename == 'Data2scaled.txt': \n",
        "            name.append(filename)\n",
        "            raw_data = np.genfromtxt('data/etalon_etalon_29May20.ccfSum-telemetry.csv',delimiter=',',names=True)\n",
        "            feature_list.append(list(raw_data.dtype.names))\n",
        "            test_data = data_matrix[:,[i for i in range(len(data_matrix[1])) if i!=1]]\n",
        "            test_target = data_matrix[:,1]\n",
        "        else:\n",
        "            train_data_list.append(data_matrix[:,[i for i in range(len(data_matrix[1])) if i!=1]])\n",
        "            train_target_list.append(data_matrix[:,1])\n",
        "    feature_list = feature_list[0]\n",
        "    feature_list.remove('RV')    \n",
        "\n",
        "\n",
        "    if t == True:\n",
        "      train_data_list = [quantile_transform(data,n_quantiles=100,copy=True) for data in train_data_list]\n",
        "      test_data = quantile_transform(test_data,n_quantiles=100,copy=True)\n",
        "      train_data_torch = [torch.from_numpy(data).unsqueeze(dim=1).float().to(gpu) for data in train_data_list]\n",
        "      train_target_torch = [torch.from_numpy(data).unsqueeze(dim=1).float().to(gpu) for data in train_target_list]\n",
        "      test_data_torch, test_target_torch = torch.from_numpy(np.array(test_data)).unsqueeze(dim=1).float().to(gpu), torch.from_numpy(np.array(test_target)).float().to(gpu)\n",
        "      return train_data_torch, train_target_torch, test_data_torch, test_target_torch, np.array(feature_list,dtype=str)\n",
        "\n",
        "    \n",
        "    elif t == False:\n",
        "      train_data_list = [quantile_transform(data,n_quantiles=100,copy=True) for data in train_data_list]\n",
        "      test_data = quantile_transform(test_data,n_quantiles=100,copy=True)\n",
        "      train_data = np.concatenate(train_data_list, axis=0)\n",
        "      train_target = np.concatenate(train_target_list, axis=0)\n",
        "      train_data = np.delete(train_data, 0, 1)\n",
        "      test_data = np.delete(test_data, 0, 1)\n",
        "      return train_data, train_target, test_data, test_target, name[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29po0sRCdqWK",
        "colab_type": "text"
      },
      "source": [
        "**Loading in data:** For gpu (torch-based, t=True) and cpu (sklearn-based, t=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0PvAGEGOkih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_torch, train_target_torch, test_data_torch, test_target_torch, feature_list = loaddata('Scaleddata', t=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQqn7JXe2MXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_numpy, train_target_numpy, test_data_numpy, test_target_numpy, name = loaddata('Scaleddata', t=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SpkwRMu6ESC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, inputsize, layers, hiddensize, drop_out):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.inputsize = inputsize\n",
        "        self.hiddensize = hiddensize\n",
        "        self.layers = layers\n",
        "        self.drop_out = drop_out\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.inputsize, hidden_size = self.hiddensize, num_layers=layers, dropout=drop_out)\n",
        "        self.hidden2radial = nn.Linear(in_features=hiddensize, out_features=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        #x = F.elu(x)\n",
        "        x = self.hidden2radial(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTo46Fq2dNqe",
        "colab_type": "text"
      },
      "source": [
        "**Bayesian Optimization:** A generalized version to optimize both torch based and sklearn based algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3bCGJxUHhIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val(inputsize: int, algorithm, data, targets, **params):\n",
        "    param_list = list()\n",
        "    for arg in params.values():\n",
        "      param_list.append(arg)\n",
        "\n",
        "    if algorithm == LSTMTagger:\n",
        "      estimator = algorithm(inputsize, int(param_list[2]), int(param_list[1]), param_list[0])\n",
        "      optimizer = torch.optim.Adam(estimator.parameters(),lr=param_list[3])\n",
        "      judge = list()\n",
        "      estimator = estimator.to(gpu)\n",
        "      criterion = nn.MSELoss()\n",
        "      for i,valdata in enumerate(train_data_torch):\n",
        "          traindata = train_data_torch[:i] + train_data_torch[i+1:]\n",
        "          traintarget = train_target_torch[:i] + train_target_torch[i+1:]\n",
        "          valtarget = train_target_torch[i]\n",
        "          judge_list = list()\n",
        "          n_epochs = 100\n",
        "          for e in range(n_epochs):\n",
        "            estimator.train()\n",
        "            epoch_losses = list()\n",
        "            epoch_evs = list()\n",
        "            acc_list = list()\n",
        "            loss_list = list()\n",
        "            for batch in range(len(traindata)):\n",
        "              estimator.zero_grad()\n",
        "              optimizer.zero_grad() \n",
        "              prediction = estimator(traindata[batch])\n",
        "              target = traintarget[batch]\n",
        "              # Calculating the loss function\n",
        "              loss = criterion(prediction.squeeze(dim=2), target)\n",
        "              # Calculating the gradient\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "            with torch.no_grad():\n",
        "              estimator.eval()\n",
        "              train_prediction = estimator(valdata).squeeze(dim=1)\n",
        "              loss_list.append( float(criterion((train_prediction),valtarget).detach().cpu()) )\n",
        "              acc_list.append( explained_variance_score(valtarget.cpu(), train_prediction.cpu()) )\n",
        "              #print(e, np.mean(loss_list),np.mean(acc_list))\n",
        "            judge_list.append(np.mean(acc_list))\n",
        "      return np.mean(judge_list)\n",
        "\n",
        "    else:\n",
        "      for key in params.keys():\n",
        "        if params[key] >= 1:\n",
        "          params[key] = int(params[key])\n",
        "      estimator = algorithm(random_state=27, **params)\n",
        "      cval = cross_val_score(estimator, data, targets, cv=5,scoring='explained_variance')\n",
        "      return cval.mean()\n",
        "\n",
        "def optimize(algorithm, data, targets, params, n_iter):\n",
        "    def crossval_wrapper(data=data, targets=targets, **params):\n",
        "        return val(inputsize = 27,\n",
        "                   algorithm = algorithm, \n",
        "                   data = data, \n",
        "                   targets = targets, \n",
        "                   **params)\n",
        "\n",
        "    optimizer = BayesianOptimization(f=crossval_wrapper, \n",
        "                                     pbounds=params, \n",
        "                                     random_state=27, \n",
        "                                     verbose=2)\n",
        "    optimizer.maximize(init_points=2, n_iter=n_iter)\n",
        "\n",
        "    return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrLZo9b3nlvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_list = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVsm6am4dHyV",
        "colab_type": "text"
      },
      "source": [
        "**Long short term memory:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVWYj3SF6I6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "36bd4abe-8c73-4515-9694-b2e6dbb1b225"
      },
      "source": [
        "params_LSTM = {\"layers\": (1, 3),\n",
        "               \"hiddensize\": (100, 400),\n",
        "               \"drop_out\": (0.2, 0.6),\n",
        "               \"lr\": (0.0001, 0.00001)}\n",
        "\n",
        "BO_LSTM = optimize(algorithm = LSTMTagger, data = train_data_torch, targets = train_target_torch, params = params_LSTM, n_iter = 6)\n",
        "\n",
        "print(BO_LSTM.max)\n",
        "\n",
        "max_params_LSTM = BO_LSTM.max['params']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | drop_out  | hidden... |  layers   |    lr     |\n",
            "-------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8388  \u001b[0m | \u001b[0m 0.3703  \u001b[0m | \u001b[0m 344.4   \u001b[0m | \u001b[0m 2.471   \u001b[0m | \u001b[0m 2.188e-0\u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.883   \u001b[0m | \u001b[95m 0.3534  \u001b[0m | \u001b[95m 393.8   \u001b[0m | \u001b[95m 2.786   \u001b[0m | \u001b[95m 8.113e-0\u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5794010593306493 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7524  \u001b[0m | \u001b[0m 0.5794  \u001b[0m | \u001b[0m 399.7   \u001b[0m | \u001b[0m 1.009   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.602   \u001b[0m | \u001b[0m 0.5163  \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 2.35    \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.2294  \u001b[0m | \u001b[0m 216.7   \u001b[0m | \u001b[0m 2.987   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6417  \u001b[0m | \u001b[0m 0.4732  \u001b[0m | \u001b[0m 124.3   \u001b[0m | \u001b[0m 2.692   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.266604824910106 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7216  \u001b[0m | \u001b[0m 0.2666  \u001b[0m | \u001b[0m 391.4   \u001b[0m | \u001b[0m 1.813   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7725  \u001b[0m | \u001b[0m 0.2024  \u001b[0m | \u001b[0m 298.0   \u001b[0m | \u001b[0m 2.896   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n",
            "=========================================================================\n",
            "{'target': 0.8829647785425186, 'params': {'drop_out': 0.3533523091490481, 'hiddensize': 393.83698964335616, 'layers': 2.7863886934302706, 'lr': 8.112563472210621e-05}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7MiK4ZDGvwb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cfeac567-1e33-4fdd-8005-89686f8be32b"
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "judge = list()\n",
        "for i,valdata in enumerate(train_data_torch):\n",
        "      model = LSTMTagger(27,layers=int(max_params_LSTM['layers']), hiddensize=int(max_params_LSTM['hiddensize']),drop_out=max_params_LSTM['drop_out']).to(gpu)\n",
        "      optimizer = optim.Adam(model.parameters(),lr=max_params_LSTM['lr'])\n",
        "\n",
        "      traindata = train_data_torch[:i] + train_data_torch[i+1:]\n",
        "      traintarget = train_target_torch[:i] + train_target_torch[i+1:]\n",
        "      valtarget = train_target_torch[i]\n",
        "      judge_list = list()\n",
        "\n",
        "      plotlosses = PlotLosses()\n",
        "      n_epochs = 100\n",
        "      for e in range(n_epochs):\n",
        "          model.train()\n",
        "          epoch_losses = list()\n",
        "          epoch_evs = list()\n",
        "          acc_list = list()\n",
        "          loss_list = list()\n",
        "          for batch in range(len(traindata)):\n",
        "              model.zero_grad()\n",
        "              optimizer.zero_grad() \n",
        "              prediction = model(traindata[batch])\n",
        "              target = traintarget[batch]\n",
        "              # Calculating the loss function\n",
        "              loss = criterion(prediction.squeeze(dim=2), target)\n",
        "              epoch_losses.append(float(loss))\n",
        "              evs = explained_variance_score(target.squeeze(dim=1).detach().cpu().numpy(),prediction.squeeze(dim=1).detach().cpu().numpy())\n",
        "              epoch_evs.append(evs)\n",
        "              # Calculating the gradient\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "          with torch.no_grad():\n",
        "              model.eval()\n",
        "              train_prediction = model(valdata).squeeze(dim=1)\n",
        "              loss_list.append( float(criterion((train_prediction),valtarget).detach().cpu()) )\n",
        "              acc_list.append( explained_variance_score(valtarget.cpu(), train_prediction.cpu()) )\n",
        "          print(e, np.mean(epoch_losses), np.mean(epoch_evs))\n",
        "          judge_list.append(np.mean(acc_list))\n",
        "      judge.append([np.mean(judge_list),model])\n",
        "sorted(judge, key=lambda x: x[0])\n",
        "winner = judge[0]\n",
        "model_list.append(winner[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.9958789745966593 0.004728456338246663\n",
            "1 0.9819310307502747 0.01888968547185262\n",
            "2 0.9689929882685343 0.032029410203297935\n",
            "3 0.9536724289258321 0.04754668474197388\n",
            "4 0.9367795586585999 0.06469591458638509\n",
            "5 0.9169230858484904 0.0848168134689331\n",
            "6 0.8918176889419556 0.11026948690414429\n",
            "7 0.8640719453493754 0.13877445459365845\n",
            "8 0.8245387673377991 0.17921713987986246\n",
            "9 0.7697240511576334 0.23564298947652182\n",
            "10 0.6975667675336202 0.3103318214416504\n",
            "11 0.5955915252367655 0.41737620035807294\n",
            "12 0.45896201332410175 0.5614033341407776\n",
            "13 0.3101878861586253 0.7133896748224894\n",
            "14 0.25648847470680874 0.7623393138249716\n",
            "15 0.2794727385044098 0.7434447606404623\n",
            "16 0.2166900336742401 0.7867833971977234\n",
            "17 0.19837850332260132 0.80556720495224\n",
            "18 0.20679772396882376 0.7986060579617819\n",
            "19 0.20344978074232736 0.8012906511624655\n",
            "20 0.1898506060242653 0.8135952353477478\n",
            "21 0.1727204049626986 0.8317118684450785\n",
            "22 0.1655131864051024 0.8398224910100301\n",
            "23 0.16459576164682707 0.8410017490386963\n",
            "24 0.15950894231597582 0.8457172711690267\n",
            "25 0.15186131124695143 0.8525966008504232\n",
            "26 0.147983534882466 0.8567473292350769\n",
            "27 0.14179499944051108 0.8624815940856934\n",
            "28 0.13858092948794365 0.8657755454381307\n",
            "29 0.13214197382330894 0.8727855483690897\n",
            "30 0.1305282562971115 0.8741627335548401\n",
            "31 0.12651623288790384 0.8784792820612589\n",
            "32 0.12071473896503448 0.883974572022756\n",
            "33 0.11603534718354543 0.8883570035298666\n",
            "34 0.11134527499477069 0.8920887112617493\n",
            "35 0.11103441069523494 0.8932641545931498\n",
            "36 0.10950336108605067 0.8936971028645834\n",
            "37 0.10056709249814351 0.9022173881530762\n",
            "38 0.10072601214051247 0.9014843304951986\n",
            "39 0.09966565916935603 0.9024309913317362\n",
            "40 0.0936024139324824 0.9082702199618021\n",
            "41 0.09148382768034935 0.909637987613678\n",
            "42 0.09061752383907636 0.9100183645884196\n",
            "43 0.08710535491506259 0.9130491813023885\n",
            "44 0.08513481418291728 0.9150153199831644\n",
            "45 0.08500207836429279 0.9151075085004171\n",
            "46 0.08448456848661105 0.9156432151794434\n",
            "47 0.08396337057153384 0.9162302414576212\n",
            "48 0.08606039981047313 0.914098302523295\n",
            "49 0.08029826854666074 0.9199013710021973\n",
            "50 0.08138436203201611 0.9187373916308085\n",
            "51 0.07979145273566246 0.920666515827179\n",
            "52 0.08036158854762714 0.9197419881820679\n",
            "53 0.07766393944621086 0.9232420523961385\n",
            "54 0.07745006307959557 0.9230311910311381\n",
            "55 0.0756891556084156 0.9248053232828776\n",
            "56 0.07567634557684262 0.9248409072558085\n",
            "57 0.07452375441789627 0.925713857014974\n",
            "58 0.07405185078581174 0.927498996257782\n",
            "59 0.07151488711436589 0.9293078382809957\n",
            "60 0.07242774590849876 0.9294543663660685\n",
            "61 0.0722832481066386 0.9284642736117045\n",
            "62 0.07198893030484517 0.9299538930257162\n",
            "63 0.07273509725928307 0.9274791876475016\n",
            "64 0.07154378419121106 0.9319663445154825\n",
            "65 0.0676441416144371 0.9332634210586548\n",
            "66 0.06697993973890941 0.935214618841807\n",
            "67 0.07058958957592647 0.9300903081893921\n",
            "68 0.06672872727115949 0.9356290499369303\n",
            "69 0.0685306986172994 0.9327306548754374\n",
            "70 0.06631328786412875 0.9377089738845825\n",
            "71 0.06717325622836749 0.934528668721517\n",
            "72 0.06626199061671893 0.9364997347195944\n",
            "73 0.06586903582016627 0.934786299864451\n",
            "74 0.06446607907613118 0.9389767448107401\n",
            "75 0.06274905055761337 0.9376357992490133\n",
            "76 0.06540417298674583 0.9405079086621603\n",
            "77 0.06475027153889339 0.9363434910774231\n",
            "78 0.06446345026294391 0.9391599297523499\n",
            "79 0.06081842755277952 0.9399415850639343\n",
            "80 0.060836890091498695 0.9427027901013693\n",
            "81 0.06095223128795624 0.9401368896166483\n",
            "82 0.06135767077406248 0.942363957564036\n",
            "83 0.060812429835398994 0.9404520392417908\n",
            "84 0.05973041305939356 0.9454008539517721\n",
            "85 0.059453011800845466 0.9409719109535217\n",
            "86 0.059533752501010895 0.9440368413925171\n",
            "87 0.05947729821006457 0.941103458404541\n",
            "88 0.05919079606731733 0.9463204940160116\n",
            "89 0.059177915255228676 0.9414857824643453\n",
            "90 0.057763464748859406 0.9480681618054708\n",
            "91 0.05952013283967972 0.9414721528689066\n",
            "92 0.05727238580584526 0.9483430782953898\n",
            "93 0.05989746997753779 0.940923273563385\n",
            "94 0.057284059623877205 0.9471642971038818\n",
            "95 0.05514939253528913 0.9455365737279257\n",
            "96 0.05496028810739517 0.9507140517234802\n",
            "97 0.053822255382935204 0.9472283522288004\n",
            "98 0.05427838241060575 0.9506786266962687\n",
            "99 0.05587815369168917 0.9447507659594218\n",
            "0 0.9992913206418356 0.0025567213694254556\n",
            "1 0.9894044001897176 0.011587679386138916\n",
            "2 0.9791306257247925 0.02123759190241496\n",
            "3 0.9710211753845215 0.02903588612874349\n",
            "4 0.9608040054639181 0.039213856061299644\n",
            "5 0.9474461476008097 0.05269026756286621\n",
            "6 0.9338423609733582 0.06649722655614217\n",
            "7 0.9153992335001627 0.08517279227574666\n",
            "8 0.8946173985799154 0.10621798038482666\n",
            "9 0.8620720704396566 0.13893387715021768\n",
            "10 0.8229547341664633 0.17848296960194907\n",
            "11 0.7645118236541748 0.2375862995783488\n",
            "12 0.6846298575401306 0.3187670310338338\n",
            "13 0.5682870348294576 0.43828026453653973\n",
            "14 0.43875838319460553 0.5731169978777567\n",
            "15 0.3779479116201401 0.6303936839103699\n",
            "16 0.4176034430662791 0.6200545231501261\n",
            "17 0.3810936162869136 0.6535375118255615\n",
            "18 0.3507276847958565 0.6630425254503886\n",
            "19 0.34232550859451294 0.6670153339703878\n",
            "20 0.3408301422993342 0.6656266848246256\n",
            "21 0.3206314245859782 0.686521569887797\n",
            "22 0.3040471648176511 0.7037792205810547\n",
            "23 0.2918159564336141 0.7150845130284628\n",
            "24 0.2857043171922366 0.7229782938957214\n",
            "25 0.2790901263554891 0.7332325379053751\n",
            "26 0.26545383036136627 0.7452599008878072\n",
            "27 0.2540676991144816 0.7564117908477783\n",
            "28 0.25184500217437744 0.7605206569035848\n",
            "29 0.24079712977012 0.7667445540428162\n",
            "30 0.23597980290651321 0.7668736775716146\n",
            "31 0.23185368378957114 0.7792519529660543\n",
            "32 0.2414203186829885 0.7663344144821167\n",
            "33 0.2436810409029325 0.7771780888239542\n",
            "34 0.2659811278184255 0.7497965097427368\n",
            "35 0.23443841685851416 0.7819211483001709\n",
            "36 0.2382327119509379 0.771161158879598\n",
            "37 0.23203070958455405 0.7713417410850525\n",
            "38 0.22214534878730774 0.7841046253840128\n",
            "39 0.22210166851679483 0.7880415916442871\n",
            "40 0.22010676811138788 0.7837501366933187\n",
            "41 0.21751114477713904 0.7910520831743876\n",
            "42 0.21233910073836645 0.7958278258641561\n",
            "43 0.20788547893365225 0.7970038453737894\n",
            "44 0.20775715013345084 0.7975452542304993\n",
            "45 0.20211241642634073 0.803955614566803\n",
            "46 0.20038093502322832 0.8025657534599304\n",
            "47 0.19680110489328703 0.8066173195838928\n",
            "48 0.19534359003106752 0.8078445792198181\n",
            "49 0.19238868231574693 0.8100589911142985\n",
            "50 0.1897114490469297 0.8126055002212524\n",
            "51 0.18952866519490877 0.8133335709571838\n",
            "52 0.18411284436782202 0.8199279109636942\n",
            "53 0.18510800848404566 0.817444900671641\n",
            "54 0.17921901494264603 0.8233645359675089\n",
            "55 0.17907172193129858 0.8248846530914307\n",
            "56 0.1767714967330297 0.8253592650095621\n",
            "57 0.17121857528885207 0.8312758803367615\n",
            "58 0.1696941815316677 0.833102305730184\n",
            "59 0.16622243945797285 0.8355392018953959\n",
            "60 0.16700105369091034 0.8352523446083069\n",
            "61 0.1611743246515592 0.8409954110781351\n",
            "62 0.15805399417877197 0.8451813062032064\n",
            "63 0.15470668797691664 0.846537450949351\n",
            "64 0.1511047581831614 0.8508005340894064\n",
            "65 0.15056291595101357 0.8507657249768575\n",
            "66 0.148396714280049 0.8538698554039001\n",
            "67 0.14205168187618256 0.8605973323186239\n",
            "68 0.14018814265727997 0.8632013003031412\n",
            "69 0.1436516965428988 0.8629408081372579\n",
            "70 0.13650953645507494 0.8665873010953268\n",
            "71 0.1328035108745098 0.8706761399904887\n",
            "72 0.13306822255253792 0.8691352605819702\n",
            "73 0.13026865075031915 0.8707881967226664\n",
            "74 0.1267888123790423 0.8751999537150065\n",
            "75 0.12545404583215714 0.8847155769666036\n",
            "76 0.12882956489920616 0.8777234156926473\n",
            "77 0.12593833977977434 0.8779853185017904\n",
            "78 0.1254847211142381 0.8842884500821432\n",
            "79 0.1255540649096171 0.8749187787373861\n",
            "80 0.11860436946153641 0.8830118974049886\n",
            "81 0.11928066487113635 0.8857702016830444\n",
            "82 0.11880322049061458 0.8918421864509583\n",
            "83 0.11910863717397054 0.8816711107889811\n",
            "84 0.11972953006625175 0.8912911415100098\n",
            "85 0.1294990343352159 0.8772130807240804\n",
            "86 0.12536505609750748 0.8824346462885538\n",
            "87 0.12611144284407297 0.8849674463272095\n",
            "88 0.11960998053352039 0.8857361276944479\n",
            "89 0.11577469483017921 0.8890728155771891\n",
            "90 0.11204259842634201 0.8912860751152039\n",
            "91 0.1110542081296444 0.891949454943339\n",
            "92 0.11413708453377087 0.8907626072565714\n",
            "93 0.11152329668402672 0.8940906723340353\n",
            "94 0.1136351836224397 0.8911104202270508\n",
            "95 0.11290372163057327 0.8911881248156229\n",
            "96 0.10922919834653537 0.8948875268300375\n",
            "97 0.11086483051379521 0.8928533792495728\n",
            "98 0.10797841846942902 0.8963760534922282\n",
            "99 0.110676442583402 0.8956436713536581\n",
            "0 1.0015230576197307 -0.0015093485514322917\n",
            "1 0.9898026784261068 0.010227819283803305\n",
            "2 0.9784223635991415 0.021675984064737957\n",
            "3 0.9658328890800476 0.03435866038004557\n",
            "4 0.9531965057055155 0.04714409510294596\n",
            "5 0.938075323899587 0.06240922212600708\n",
            "6 0.9198318918546041 0.08085489273071289\n",
            "7 0.895347793896993 0.10567647218704224\n",
            "8 0.8703611493110657 0.1311458945274353\n",
            "9 0.8321370482444763 0.16994168361028036\n",
            "10 0.7817170818646749 0.22151933113733926\n",
            "11 0.715916653474172 0.2894584933916728\n",
            "12 0.62769948442777 0.3813311258951823\n",
            "13 0.515044758717219 0.5011443098386129\n",
            "14 0.4149295687675476 0.6098801493644714\n",
            "15 0.4051366870601972 0.6306157906850179\n",
            "16 0.41823144257068634 0.6510977347691854\n",
            "17 0.36825163165728253 0.6720089912414551\n",
            "18 0.35646846145391464 0.6645332177480062\n",
            "19 0.3540821274121602 0.6613125403722128\n",
            "20 0.3519452561934789 0.6597557067871094\n",
            "21 0.3409099628527959 0.6688033938407898\n",
            "22 0.32833069066206616 0.6839430729548136\n",
            "23 0.32825248936812085 0.6874528129895529\n",
            "24 0.3238622496525447 0.6902329723040262\n",
            "25 0.31734030197064084 0.6934428811073303\n",
            "26 0.3120195344090462 0.6968770623207092\n",
            "27 0.3097846483190854 0.6985616882642111\n",
            "28 0.30272816866636276 0.7075658837954203\n",
            "29 0.3030558576186498 0.7073609630266825\n",
            "30 0.2936381126443545 0.7161798675855001\n",
            "31 0.2902357379595439 0.7195800542831421\n",
            "32 0.2878291184703509 0.7215301195780436\n",
            "33 0.2831900119781494 0.7257368167241415\n",
            "34 0.2769206178685029 0.7328179876009623\n",
            "35 0.2766043034692605 0.7330933014551798\n",
            "36 0.26958319917321205 0.740555981794993\n",
            "37 0.2670266330242157 0.7428418000539144\n",
            "38 0.2629290235539277 0.7456555167833964\n",
            "39 0.2627369376520316 0.7463432351748148\n",
            "40 0.25354395310084027 0.7556797663370768\n",
            "41 0.25031041353940964 0.7587274710337321\n",
            "42 0.24239681661128998 0.7662767171859741\n",
            "43 0.2376502069334189 0.7712743878364563\n",
            "44 0.23467125122745833 0.773660143216451\n",
            "45 0.23121017465988794 0.7784449458122253\n",
            "46 0.22381310909986496 0.7850016554196676\n",
            "47 0.2198257471124331 0.788493275642395\n",
            "48 0.21340868373711905 0.7960447470347086\n",
            "49 0.20876227443416914 0.799709419409434\n",
            "50 0.20207189147671065 0.8071225682894388\n",
            "51 0.19989228000243506 0.8088390628496805\n",
            "52 0.19025468826293945 0.8174374103546143\n",
            "53 0.1881087844570478 0.8208525975545248\n",
            "54 0.1834537461400032 0.824211835861206\n",
            "55 0.17676256969571114 0.8300484816233317\n",
            "56 0.17334691062569618 0.8324879209200541\n",
            "57 0.169941616555055 0.8369447787602743\n",
            "58 0.16405028601487479 0.8424383600552877\n",
            "59 0.16231806948781013 0.841809888680776\n",
            "60 0.15690275405844054 0.8472471237182617\n",
            "61 0.15567426507671675 0.8492502570152283\n",
            "62 0.15338348100582758 0.851844072341919\n",
            "63 0.1483976406355699 0.855552097161611\n",
            "64 0.14654082680741945 0.8547031283378601\n",
            "65 0.14307466025153795 0.8617752393086752\n",
            "66 0.13998480079074702 0.8614972233772278\n",
            "67 0.1378844411422809 0.8657272855440775\n",
            "68 0.13681074976921082 0.8674301505088806\n",
            "69 0.13182302688558897 0.8706838488578796\n",
            "70 0.12957815391321978 0.8796613613764445\n",
            "71 0.12711622193455696 0.8738428950309753\n",
            "72 0.12732753530144691 0.8770379622777303\n",
            "73 0.12632854717473188 0.8802316387494405\n",
            "74 0.12618669060369334 0.8740934729576111\n",
            "75 0.12165944340328376 0.8860191702842712\n",
            "76 0.12340258186062177 0.8831931153933207\n",
            "77 0.12142250811060269 0.882515033086141\n",
            "78 0.1155723799020052 0.8935353954633077\n",
            "79 0.11473848794897397 0.8868267933527628\n",
            "80 0.10994031218190987 0.8957342902819315\n",
            "81 0.10763365340729554 0.8945525487263998\n",
            "82 0.10888970332841079 0.8939817349116007\n",
            "83 0.10944562715788682 0.8957986434300741\n",
            "84 0.10647485467294852 0.8986781636873881\n",
            "85 0.11519061277310054 0.8878005146980286\n",
            "86 0.11445627237359683 0.8963026801745096\n",
            "87 0.12043676773707072 0.8868454893430074\n",
            "88 0.11171810949842136 0.8926177422205607\n",
            "89 0.11072058975696564 0.898834764957428\n",
            "90 0.10453728524347146 0.9015763799349467\n",
            "91 0.11379564553499222 0.889443059762319\n",
            "92 0.12035406877597173 0.9005055824915568\n",
            "93 0.114789633701245 0.8905140161514282\n",
            "94 0.10711975644032161 0.9051589965820312\n",
            "95 0.12477587970594566 0.884867529074351\n",
            "96 0.11543261383970578 0.9103224476178488\n",
            "97 0.11223964020609856 0.8980926473935446\n",
            "98 0.10209909888605277 0.901922881603241\n",
            "99 0.10218497676153977 0.9096973737080892\n",
            "0 1.0012544393539429 0.00033982594807942707\n",
            "1 0.9898783167203268 0.01114328702290853\n",
            "2 0.9795332948366801 0.02119678258895874\n",
            "3 0.9693206946055094 0.031216780344645183\n",
            "4 0.9577297965685526 0.042660295963287354\n",
            "5 0.9446641008059183 0.0556406577428182\n",
            "6 0.9286747376124064 0.07156749566396077\n",
            "7 0.907949169476827 0.09228696425755818\n",
            "8 0.8830592632293701 0.11718525489171346\n",
            "9 0.8517244458198547 0.1485795577367147\n",
            "10 0.8074944814046224 0.19296189149220785\n",
            "11 0.7446337540944418 0.256087859471639\n",
            "12 0.6607320110003153 0.34068357944488525\n",
            "13 0.5335122545560201 0.4688572883605957\n",
            "14 0.36820536355177563 0.6365580558776855\n",
            "15 0.24549568941195807 0.7662541270256042\n",
            "16 0.3667220026254654 0.6785818735758463\n",
            "17 0.285826841990153 0.7355327208836874\n",
            "18 0.2507498512665431 0.7575735251108805\n",
            "19 0.2474911759297053 0.7589794596036276\n",
            "20 0.2573234165708224 0.7534265518188477\n",
            "21 0.24112056195735931 0.7677978674570719\n",
            "22 0.22182898968458176 0.7829753160476685\n",
            "23 0.21855972707271576 0.7841322223345438\n",
            "24 0.2206359306971232 0.7810361782709757\n",
            "25 0.21611151099205017 0.7857514421145121\n",
            "26 0.20893247922261557 0.7927750547726949\n",
            "27 0.20638399198651314 0.796196440855662\n",
            "28 0.2049462360640367 0.7978878021240234\n",
            "29 0.19766496618588766 0.8039190173149109\n",
            "30 0.19329960023363432 0.8087104956309\n",
            "31 0.1912624997397264 0.8109956979751587\n",
            "32 0.18963015700380007 0.8128045996030172\n",
            "33 0.18215754007299742 0.820036252339681\n",
            "34 0.17996947218974432 0.8219765226046244\n",
            "35 0.17521080995599428 0.8275434573491415\n",
            "36 0.1759655885398388 0.8269177079200745\n",
            "37 0.17115349198381105 0.831805964310964\n",
            "38 0.16618102168043455 0.8361905415852865\n",
            "39 0.16557449847459793 0.8366701205571493\n",
            "40 0.15794135505954424 0.8449431856473287\n",
            "41 0.1546723060309887 0.8474072217941284\n",
            "42 0.15218361839652061 0.8497118949890137\n",
            "43 0.14881126706798872 0.8536080718040466\n",
            "44 0.1438339799642563 0.8580596645673116\n",
            "45 0.145310298850139 0.8563485542933146\n",
            "46 0.13817266002297401 0.8645130197207133\n",
            "47 0.13465829441944757 0.8670372366905212\n",
            "48 0.1321099909643332 0.8694014946619669\n",
            "49 0.1284607301155726 0.8744516571362814\n",
            "50 0.12303867439428966 0.8783800005912781\n",
            "51 0.11959052830934525 0.8812381625175476\n",
            "52 0.11514195675651233 0.8862800002098083\n",
            "53 0.11028087760011356 0.8917033274968466\n",
            "54 0.11069886386394501 0.8899269302686056\n",
            "55 0.10744135578473409 0.8964702089627584\n",
            "56 0.10198489079872768 0.8988251884778341\n",
            "57 0.10653751095136006 0.8950524727503458\n",
            "58 0.1003749097386996 0.9006414810816447\n",
            "59 0.09597747400403023 0.9044913252194723\n",
            "60 0.09396696339050929 0.9084161520004272\n",
            "61 0.09230458984772365 0.9104036092758179\n",
            "62 0.09303299834330876 0.911199688911438\n",
            "63 0.08977802842855453 0.9105588595072428\n",
            "64 0.08812741314371426 0.914393405119578\n",
            "65 0.08545902619759242 0.9147433638572693\n",
            "66 0.08279231935739517 0.919474720954895\n",
            "67 0.08015107239286105 0.9206412235895792\n",
            "68 0.07941079139709473 0.9223910371462504\n",
            "69 0.07621239498257637 0.9247775872548422\n",
            "70 0.07593390283485253 0.9259487589200338\n",
            "71 0.07336789121230443 0.9281633098920187\n",
            "72 0.07203132100403309 0.9283722837766012\n",
            "73 0.07106529052058856 0.9316256046295166\n",
            "74 0.07079658408959706 0.9299817482630411\n",
            "75 0.0669878280411164 0.9340798854827881\n",
            "76 0.06782316106061141 0.9336630702018738\n",
            "77 0.06464602922399838 0.9361326694488525\n",
            "78 0.06206780175367991 0.939018448193868\n",
            "79 0.06338875430325668 0.9412088592847189\n",
            "80 0.0636566827694575 0.9397382934888204\n",
            "81 0.060086738939086594 0.9401603738466898\n",
            "82 0.06005306914448738 0.9422353704770406\n",
            "83 0.056895347932974495 0.9432035883267721\n",
            "84 0.06025745595494906 0.9481614629427592\n",
            "85 0.054577684650818505 0.947329580783844\n",
            "86 0.05440971379478773 0.9461045861244202\n",
            "87 0.05129939317703247 0.9508646925290426\n",
            "88 0.05107634017864863 0.9496162931124369\n",
            "89 0.0514319638411204 0.9508397181828817\n",
            "90 0.050145965069532394 0.9515583713849386\n",
            "91 0.047599853947758675 0.9531612594922384\n",
            "92 0.04640108595291773 0.955222487449646\n",
            "93 0.04607086628675461 0.9545572201410929\n",
            "94 0.04431188106536865 0.9560385942459106\n",
            "95 0.0504087849209706 0.9562374949455261\n",
            "96 0.048561904579401016 0.9544748663902283\n",
            "97 0.04878154769539833 0.9517324566841125\n",
            "98 0.04726199060678482 0.9597045381863912\n",
            "99 0.050102876499295235 0.9539518157641093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIllPyl9dCHu",
        "colab_type": "text"
      },
      "source": [
        "**Light GBM:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ljVMPa9F0BZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "34634a42-1b6a-4b02-e3e9-e7fb1c9777e6"
      },
      "source": [
        "params_LGBM = {'num_leaves': (2, 5),\n",
        "               #'max_depth': (50, 500),\n",
        "               'learning_rate': (0.01, 1)}\n",
        "\n",
        "BO_LGBM = optimize(algorithm = lgb.LGBMRegressor, data = train_data_numpy, targets = train_target_numpy, params = params_LGBM, n_iter=30)\n",
        "\n",
        "print(BO_LGBM.max)\n",
        "\n",
        "max_params_LGBM = BO_LGBM.max['params']\n",
        "\n",
        "model_LGBM = lgb.LGBMRegressor(num_leaves = int(max_params_LGBM['num_leaves']), \n",
        "                               #max_depth= int(max_params_LGBM['max_depth']), \n",
        "                               learning_rate = max_params_LGBM['learning_rate']\n",
        "                               )\n",
        "model_LGBM.fit(train_data_numpy, train_target_numpy)\n",
        "\n",
        "model_list.append(model_LGBM)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | learni... | num_le... |\n",
            "-------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2035  \u001b[0m | \u001b[0m 0.4315  \u001b[0m | \u001b[0m 4.444   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.3615  \u001b[0m | \u001b[0m 0.738   \u001b[0m | \u001b[0m 4.604   \u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.1464  \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 2.0     \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.6386  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
            "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.15    \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 3.098   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.1447  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 5.0     \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.1464  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.52    \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.738   \u001b[0m |\n",
            "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.1519  \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 4.466   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.1519  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 4.116   \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.386   \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.1519  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 4.704   \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.1464  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.225   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.1498  \u001b[0m | \u001b[0m 0.01007 \u001b[0m | \u001b[0m 4.376   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.877   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.1519  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 4.802   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.1464  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.921   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.1405  \u001b[0m | \u001b[0m 0.01065 \u001b[0m | \u001b[0m 4.091   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.1243  \u001b[0m | \u001b[0m 0.01166 \u001b[0m | \u001b[0m 4.623   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2703  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.351   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.4928  \u001b[0m | \u001b[0m 0.5899  \u001b[0m | \u001b[0m 2.747   \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m-1.062   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.004   \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.8231  \u001b[0m | \u001b[0m 0.9806  \u001b[0m | \u001b[0m 4.992   \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1513  \u001b[0m | \u001b[0m 0.433   \u001b[0m | \u001b[0m 3.415   \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2095  \u001b[0m | \u001b[0m 0.3756  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.3421  \u001b[0m | \u001b[0m 0.3843  \u001b[0m | \u001b[0m 5.0     \u001b[0m |\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.6386  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.884   \u001b[0m |\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.03298 \u001b[0m | \u001b[0m 0.2297  \u001b[0m | \u001b[0m 3.063   \u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.02389 \u001b[0m | \u001b[0m 0.2313  \u001b[0m | \u001b[0m 3.835   \u001b[0m |\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.06512 \u001b[0m | \u001b[0m 0.1861  \u001b[0m | \u001b[0m 2.42    \u001b[0m |\n",
            "| \u001b[95m 31      \u001b[0m | \u001b[95m 0.1535  \u001b[0m | \u001b[95m 0.01165 \u001b[0m | \u001b[95m 2.722   \u001b[0m |\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.06584 \u001b[0m | \u001b[0m 0.121   \u001b[0m | \u001b[0m 3.508   \u001b[0m |\n",
            "=================================================\n",
            "{'target': 0.1535336409126924, 'params': {'learning_rate': 0.011648459370649374, 'num_leaves': 2.7218980502985026}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oag1LLnWc5bs",
        "colab_type": "text"
      },
      "source": [
        "**XG Boost:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXTtPVSyu4sm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0aa17b2-5755-4447-e1a3-309263928c36"
      },
      "source": [
        "params_XGB = {\"eta\": (0.1, 0.5),\n",
        "               \"max_depth\": (1, 10),\n",
        "               \"num_round\": (1, 40)}\n",
        "\n",
        "BO_XGB = optimize(algorithm = xgb.XGBRegressor, data = train_data_numpy, targets = train_target_numpy, params = params_XGB, n_iter=30)\n",
        "\n",
        "print(BO_XGB.max)\n",
        "\n",
        "max_params_XGB = BO_XGB.max['params']\n",
        "\n",
        "model_XGB = xgb.XGBRegressor(max_depth = int(max_params_XGB['max_depth']), \n",
        "                             num_round = int(max_params_XGB['num_round']),\n",
        "                             eta = max_params_XGB['eta']\n",
        "                             )             \n",
        "\n",
        "model_XGB.fit(train_data_numpy, train_target_numpy)     \n",
        "\n",
        "model_list.append(model_XGB)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   |    eta    | max_depth | num_round |\n",
            "-------------------------------------------------------------\n",
            "[19:31:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.06616 \u001b[0m | \u001b[0m 0.2703  \u001b[0m | \u001b[0m 8.331   \u001b[0m | \u001b[0m 29.68   \u001b[0m |\n",
            "[19:31:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.007345\u001b[0m | \u001b[0m 0.4472  \u001b[0m | \u001b[0m 4.45    \u001b[0m | \u001b[0m 39.2    \u001b[0m |\n",
            "[19:31:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.02946 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "[19:31:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.04771 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "[19:31:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.02946 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 19.19   \u001b[0m |\n",
            "[19:31:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.007048\u001b[0m | \u001b[0m 0.4357  \u001b[0m | \u001b[0m 9.99    \u001b[0m | \u001b[0m 18.07   \u001b[0m |\n",
            "[19:31:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.04771 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 40.0    \u001b[0m |\n",
            "[19:31:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.04771 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 34.45   \u001b[0m |\n",
            "[19:31:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.05496 \u001b[0m | \u001b[0m 0.2461  \u001b[0m | \u001b[0m 6.635   \u001b[0m | \u001b[0m 32.59   \u001b[0m |\n",
            "[19:31:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.02946 \u001b[0m | \u001b[0m 0.1527  \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m 27.86   \u001b[0m |\n",
            "[19:31:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.007048\u001b[0m | \u001b[0m 0.1015  \u001b[0m | \u001b[0m 9.848   \u001b[0m | \u001b[0m 29.49   \u001b[0m |\n",
            "[19:31:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:31:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.08217 \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 5.313   \u001b[0m | \u001b[95m 8.658   \u001b[0m |\n",
            "[19:32:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.08217 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 5.095   \u001b[0m | \u001b[0m 23.49   \u001b[0m |\n",
            "[19:32:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.04771 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 8.342   \u001b[0m |\n",
            "[19:32:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.02946 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 9.944   \u001b[0m |\n",
            "[19:32:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.08217 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 5.403   \u001b[0m | \u001b[0m 14.5    \u001b[0m |\n",
            "[19:32:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.05496 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 6.01    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "[19:32:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.08217 \u001b[0m | \u001b[0m 0.4944  \u001b[0m | \u001b[0m 5.259   \u001b[0m | \u001b[0m 28.37   \u001b[0m |\n",
            "[19:32:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.08217 \u001b[0m | \u001b[0m 0.101   \u001b[0m | \u001b[0m 5.475   \u001b[0m | \u001b[0m 4.588   \u001b[0m |\n",
            "[19:32:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.04593 \u001b[0m | \u001b[0m 0.1167  \u001b[0m | \u001b[0m 7.39    \u001b[0m | \u001b[0m 12.01   \u001b[0m |\n",
            "[19:32:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.007345\u001b[0m | \u001b[0m 0.49    \u001b[0m | \u001b[0m 4.994   \u001b[0m | \u001b[0m 18.87   \u001b[0m |\n",
            "[19:32:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.02946 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 23.79   \u001b[0m |\n",
            "[19:32:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.02946 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 40.0    \u001b[0m |\n",
            "[19:32:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.02946 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 34.79   \u001b[0m |\n",
            "[19:32:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.02946 \u001b[0m | \u001b[0m 0.4826  \u001b[0m | \u001b[0m 1.132   \u001b[0m | \u001b[0m 14.69   \u001b[0m |\n",
            "[19:32:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.04771 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 4.063   \u001b[0m |\n",
            "[19:32:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.04593 \u001b[0m | \u001b[0m 0.4788  \u001b[0m | \u001b[0m 7.782   \u001b[0m | \u001b[0m 25.25   \u001b[0m |\n",
            "[19:32:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.006426\u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 2.289   \u001b[0m | \u001b[0m 4.931   \u001b[0m |\n",
            "[19:32:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.02101 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 3.717   \u001b[0m | \u001b[0m 12.36   \u001b[0m |\n",
            "[19:32:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.04593 \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 7.334   \u001b[0m | \u001b[0m 6.152   \u001b[0m |\n",
            "[19:32:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.007048\u001b[0m | \u001b[0m 0.426   \u001b[0m | \u001b[0m 9.996   \u001b[0m | \u001b[0m 14.29   \u001b[0m |\n",
            "[19:32:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[19:32:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.02101 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 3.646   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "=============================================================\n",
            "{'target': 0.08217205767507166, 'params': {'eta': 0.5, 'max_depth': 5.313163856591104, 'num_round': 8.658346166288792}}\n",
            "[19:32:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vXlbl5le3cX",
        "colab_type": "text"
      },
      "source": [
        "**Ordinary Least Squares:** No need for Bayesian Optimization \\\\\n",
        "**Multi-Layer Perception:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcYiHBPND68R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f676780-1c72-474c-8644-42f80e0c48aa"
      },
      "source": [
        "params_MLP = {\"hidden_layer_sizes\": (1, 200),\n",
        "               \"alpha\": (0, 0.4),\n",
        "               \"learning_rate_init\": (0.00001, 1)}\n",
        "\n",
        "BO_MLP = optimize(algorithm = MLPRegressor, data = train_data_numpy, targets = train_target_numpy, params = params_MLP, n_iter=30)\n",
        "\n",
        "print(BO_MLP.max)\n",
        "\n",
        "max_params_MLP = BO_MLP.max['params']\n",
        "\n",
        "model_MLP = MLPRegressor(hidden_layer_sizes= int(max_params_MLP['hidden_layer_sizes']),\n",
        "                         alpha = max_params_MLP['alpha'],\n",
        "                         learning_rate_init= max_params_MLP['learning_rate_init']\n",
        "                         )\n",
        "model_MLP.fit(train_data_numpy, train_target_numpy)\n",
        "\n",
        "model_list.append(model_MLP)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   |   alpha   | hidden... | learni... |\n",
            "-------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2185  \u001b[0m | \u001b[0m 0.1703  \u001b[0m | \u001b[0m 163.1   \u001b[0m | \u001b[0m 0.7354  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.3975  \u001b[0m | \u001b[95m 0.3472  \u001b[0m | \u001b[95m 77.29   \u001b[0m | \u001b[95m 0.9795  \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.03076 \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.474   \u001b[0m | \u001b[0m 0.1917  \u001b[0m | \u001b[0m 75.39   \u001b[0m | \u001b[0m 0.3131  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.1674  \u001b[0m | \u001b[0m 0.3856  \u001b[0m | \u001b[0m 77.4    \u001b[0m | \u001b[0m 0.9241  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.1913  \u001b[0m | \u001b[0m 0.3907  \u001b[0m | \u001b[0m 76.42   \u001b[0m | \u001b[0m 0.9841  \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.293   \u001b[0m | \u001b[0m 0.2008  \u001b[0m | \u001b[0m 31.84   \u001b[0m | \u001b[0m 0.1787  \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.195   \u001b[0m | \u001b[0m 30.26   \u001b[0m | \u001b[0m 0.8411  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.1065  \u001b[0m | \u001b[0m 0.02639 \u001b[0m | \u001b[0m 33.51   \u001b[0m | \u001b[0m 0.5639  \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.08497 \u001b[0m | \u001b[0m 0.2349  \u001b[0m | \u001b[0m 36.0    \u001b[0m | \u001b[0m 0.008072\u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2267  \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 38.53   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.1439  \u001b[0m | \u001b[0m 0.2738  \u001b[0m | \u001b[0m 112.1   \u001b[0m | \u001b[0m 0.5374  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.2823  \u001b[0m | \u001b[0m 0.2663  \u001b[0m | \u001b[0m 114.2   \u001b[0m | \u001b[0m 0.9725  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.1078  \u001b[0m | \u001b[0m 0.0564  \u001b[0m | \u001b[0m 115.8   \u001b[0m | \u001b[0m 0.1561  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.09257 \u001b[0m | \u001b[0m 0.0791  \u001b[0m | \u001b[0m 109.7   \u001b[0m | \u001b[0m 0.5299  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.05146 \u001b[0m | \u001b[0m 0.08664 \u001b[0m | \u001b[0m 118.3   \u001b[0m | \u001b[0m 0.9661  \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.5327  \u001b[0m | \u001b[0m 0.2969  \u001b[0m | \u001b[0m 58.58   \u001b[0m | \u001b[0m 0.07666 \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.07295 \u001b[0m | \u001b[0m 0.1179  \u001b[0m | \u001b[0m 94.56   \u001b[0m | \u001b[0m 0.7638  \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.5019  \u001b[0m | \u001b[0m 0.1723  \u001b[0m | \u001b[0m 96.97   \u001b[0m | \u001b[0m 0.05128 \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.3167  \u001b[0m | \u001b[0m 0.1784  \u001b[0m | \u001b[0m 92.27   \u001b[0m | \u001b[0m 0.9519  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.008539\u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 90.87   \u001b[0m | \u001b[0m 1e-05   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.2551  \u001b[0m | \u001b[0m 0.1564  \u001b[0m | \u001b[0m 193.6   \u001b[0m | \u001b[0m 0.9409  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.04792 \u001b[0m | \u001b[0m 0.1523  \u001b[0m | \u001b[0m 191.8   \u001b[0m | \u001b[0m 0.6198  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.1172  \u001b[0m | \u001b[0m 0.2853  \u001b[0m | \u001b[0m 195.5   \u001b[0m | \u001b[0m 0.6979  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.241   \u001b[0m | \u001b[0m 0.2075  \u001b[0m | \u001b[0m 197.9   \u001b[0m | \u001b[0m 0.9755  \u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.03863 \u001b[0m | \u001b[0m 0.3904  \u001b[0m | \u001b[0m 199.6   \u001b[0m | \u001b[0m 0.02463 \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.6986  \u001b[0m | \u001b[0m 0.2569  \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 0.8225  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.06669 \u001b[0m | \u001b[0m 0.216   \u001b[0m | \u001b[0m 15.37   \u001b[0m | \u001b[0m 0.7379  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 29      \u001b[0m | \u001b[0m-4.441e-1\u001b[0m | \u001b[0m 0.3778  \u001b[0m | \u001b[0m 12.74   \u001b[0m | \u001b[0m 0.8051  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.1698  \u001b[0m | \u001b[0m 0.1482  \u001b[0m | \u001b[0m 18.0    \u001b[0m | \u001b[0m 0.5876  \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.02945 \u001b[0m | \u001b[0m 0.01158 \u001b[0m | \u001b[0m 20.17   \u001b[0m | \u001b[0m 0.5388  \u001b[0m |\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.316   \u001b[0m | \u001b[0m 0.3664  \u001b[0m | \u001b[0m 23.54   \u001b[0m | \u001b[0m 0.05381 \u001b[0m |\n",
            "=============================================================\n",
            "{'target': 0.39754287245944814, 'params': {'alpha': 0.3472012799518943, 'hidden_layer_sizes': 77.29277380165142, 'learning_rate_init': 0.9794568375781991}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMX4wqpqVRJI",
        "colab_type": "text"
      },
      "source": [
        "**Ordinary Least Squares:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcHvFwMT3Ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_OLS = linear_model.LinearRegression()\n",
        "model_OLS.fit(train_data_numpy, train_target_numpy)\n",
        "model_list.append(model_OLS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC6vHDdOVkBA",
        "colab_type": "text"
      },
      "source": [
        "**Plot:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM9hmafAhHVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "c990812c-7fd6-4471-c96f-53fafe404a1f"
      },
      "source": [
        "time = test_data_torch.cpu().squeeze().detach().numpy()[:,0]\n",
        "\n",
        "fig = plt.figure('All models')\n",
        "colorlist = ['#c51b7d', '#e9a3c9', '#fde0ef', '#e6f5d0', '#a1d76a', '#4d9221']\n",
        "#colorlist = colorlist[::-1]\n",
        "plt.plot(time, test_target_numpy, linestyle='-', linewidth=3, label='True', color=colorlist[-1])\n",
        "for i,model in enumerate(model_list):\n",
        "  if i == 0:\n",
        "    prediction = model(test_data_torch).squeeze(dim=1).detach().cpu().numpy()\n",
        "    plt.plot(time, prediction, linestyle='-',label=f'{model}'.split('(')[0].replace('Tagger',''), color=colorlist[i])\n",
        "  elif i == len(model_list)-1:\n",
        "    plt.plot(time, model.predict(test_data_numpy),linestyle='-',label=f'{model}'.split('(')[0].replace('Regression',''), color=colorlist[i])\n",
        "  else:\n",
        "    plt.plot(time, model.predict(test_data_numpy),linestyle='-',label=f'{model}'.split('(')[0].replace('Regressor',''), color=colorlist[i])\n",
        "plt.legend(loc='best')\n",
        "plt.title(f\"Testing on {name.replace('scaled.txt','')}\")\n",
        "plt.xlabel('Scaled time')\n",
        "plt.ylabel('Scaled drift')\n",
        "plt.style.use('seaborn-white')\n",
        "plt.style.use('seaborn-ticks')\n",
        "fig.patch.set_facecolor('#f2f2f2')\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywSe4IbvP0ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}